{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Checking COCO dataset(.json) file\n",
        "\n",
        "\n",
        "> annotation info가 들어있는 COCO 데이터셋을 시각적으로 확인한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "PsSQJfY2Pk1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "json_file_path = \"./dataset/train_answer.json\"\n",
        "with open(json_file_path,'r') as j:\n",
        "    contents=json.loads(j.read())"
      ],
      "metadata": {
        "id": "njUInA_uPjPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPmTyAzmPbcf"
      },
      "outputs": [],
      "source": [
        "df_img = pd.json_normalize(contents['images'])\n",
        "df_img.loc[:4]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_anno = pd.json_normalize(contents['annotations'])\n",
        "df_anno.describe()"
      ],
      "metadata": {
        "id": "ibA1EfIFPqg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_anno.loc[:8]"
      ],
      "metadata": {
        "id": "16yd24ZCPrzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modify COCO dataset\n",
        "\n",
        "\n",
        "> Training을 위해 COCO dataset을 수정한다.\n",
        "\n"
      ],
      "metadata": {
        "id": "tdVdtviWXGMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# annotations <-- id 추가 & segmentation(list(list)로 변경)\n",
        "for i in range(16848):\n",
        "  seg_list = contents['annotations'][i]['segmentation']\n",
        "  contents['annotations'][i].update({'segmentation':[seg_list]})\n",
        "  contents['annotations'][i].update({'id':i+1})"
      ],
      "metadata": {
        "id": "C2G58CSZPs6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_anno = pd.json_normalize(contents['annotations'])    \n",
        "df_anno.loc[:8]"
      ],
      "metadata": {
        "id": "k6fcyyCGPuMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# category list 추가\n",
        "category_update = [{\"supercategory\": \"estrus\", \"id\" : 1, \"name\" : \"no\"}, {\"supercategory\": \"estrus\", \"id\" : 2, \"name\" : \"yes\"}]\n",
        "contents.update({\"categories\" : category_update})"
      ],
      "metadata": {
        "id": "kPhbJl3GPv9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents[\"categories\"]"
      ],
      "metadata": {
        "id": "12DABv9xPw8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수정된 json 파일 저장\n",
        "file_save_path = \"./dataset/train_answer_modified.json\"\n",
        "with open(file_save_path,'w') as j:\n",
        "    json.dump(contents, j)"
      ],
      "metadata": {
        "id": "w-_u14OOPxuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate dataset & Train a Model\n",
        "\n",
        "> 수정한 데이터를 불러와 모델을 학습시킨다. \n",
        "  [참고코드1](https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-1-of-2-732712631047)\n",
        "\n"
      ],
      "metadata": {
        "id": "4X26LD-CPrLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "### For visualizing the outputs ###\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "H_XB2xznQD7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annFile = \"./dataset/train_answer_modified.json\"\n",
        "coco=COCO(annFile)"
      ],
      "metadata": {
        "id": "n8qWlqsDQFYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catIDs = coco.getCatIds()\n",
        "cats = coco.loadCats(catIDs)\n",
        "\n",
        "print(cats)"
      ],
      "metadata": {
        "id": "l7H2ubKEQHWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the classes (out of the 81) which you want to see. Others will not be shown.\n",
        "filterClasses = ['no', 'yes']\n",
        "\n",
        "# Fetch class IDs only corresponding to the filterClasses\n",
        "catIds = coco.getCatIds(catNms=filterClasses) \n",
        "# Get all images containing the above Category IDs\n",
        "imgIds = coco.getImgIds(catIds=catIds)\n",
        "print(\"Number of images containing all the  classes:\", len(imgIds))\n",
        "\n",
        "# load and display a random image\n",
        "img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
        "I = io.imread('./dataset/train/{}'.format(img['file_name']))/255.0\n",
        "\n",
        "plt.axis('off')\n",
        "plt.imshow(I)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HrqdgN0cQHtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and display instance annotations\n",
        "plt.imshow(I)\n",
        "plt.axis('off')\n",
        "annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
        "anns = coco.loadAnns(annIds)\n",
        "coco.showAnns(anns)"
      ],
      "metadata": {
        "id": "7PK8CeSUQKBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## ALl POSSIBLE COMBINATIONS ########\n",
        "classes = ['no', 'yes']\n",
        "\n",
        "images = []\n",
        "if classes!=None:\n",
        "    # iterate for each individual class in the list\n",
        "    for className in classes:\n",
        "        # get all images containing given class\n",
        "        catIds = coco.getCatIds(catNms=className)\n",
        "        imgIds = coco.getImgIds(catIds=catIds)\n",
        "        images += coco.loadImgs(imgIds)\n",
        "else:\n",
        "    imgIds = coco.getImgIds()\n",
        "    images = coco.loadImgs(imgIds)\n",
        "    \n",
        "# Now, filter out the repeated images    \n",
        "unique_images = []\n",
        "for i in range(len(images)):\n",
        "    if images[i] not in unique_images:\n",
        "        unique_images.append(images[i])\n",
        "\n",
        "dataset_size = len(unique_images)\n",
        "\n",
        "print(\"Number of images containing the filter classes:\", dataset_size)"
      ],
      "metadata": {
        "id": "KmyJ1t0kQLEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getClassName(classID, cats):\n",
        "    for i in range(len(cats)):\n",
        "        if cats[i]['id']==classID:\n",
        "            return cats[i]['name']\n",
        "    return \"None\""
      ],
      "metadata": {
        "id": "UrIXHFR1QrU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### GENERATE A SEGMENTATION MASK ####\n",
        "filterClasses = ['no', 'yes']\n",
        "mask = np.zeros((img['height'],img['width']))\n",
        "for i in range(len(anns)):\n",
        "    className = getClassName(anns[i]['category_id'], cats)\n",
        "    pixel_value = filterClasses.index(className)+1\n",
        "    mask = np.maximum(coco.annToMask(anns[i])*pixel_value, mask)\n",
        "plt.imshow(mask)"
      ],
      "metadata": {
        "id": "phSzDGA5REE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### GENERATE A BINARY MASK ####\n",
        "mask = np.zeros((img['height'],img['width']))\n",
        "for i in range(len(anns)):\n",
        "    mask = np.maximum(coco.annToMask(anns[i]), mask)\n",
        "plt.imshow(mask)"
      ],
      "metadata": {
        "id": "DOVhwSlcRFng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[참고 링크2](https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-2-of-2-c0d1f593096a)"
      ],
      "metadata": {
        "id": "smooZkuoRs1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filterDataset(folder, classes=None):    \n",
        "    # initialize COCO api for instance annotations\n",
        "    annFile = folder\n",
        "    coco = COCO(annFile)\n",
        "    \n",
        "    images = []\n",
        "    if classes!=None:\n",
        "        # iterate for each individual class in the list\n",
        "        for className in classes:\n",
        "            # get all images containing given categories\n",
        "            catIds = coco.getCatIds(catNms=className)\n",
        "            imgIds = coco.getImgIds(catIds=catIds)\n",
        "            images += coco.loadImgs(imgIds)\n",
        "    \n",
        "    else:\n",
        "        imgIds = coco.getImgIds()\n",
        "        images = coco.loadImgs(imgIds)\n",
        "    \n",
        "    # Now, filter out the repeated images\n",
        "    unique_images = []\n",
        "    for i in range(len(images)):\n",
        "        if images[i] not in unique_images:\n",
        "            unique_images.append(images[i])\n",
        "            \n",
        "    random.shuffle(unique_images)\n",
        "    dataset_size = len(unique_images)\n",
        "    \n",
        "    return unique_images, dataset_size, coco"
      ],
      "metadata": {
        "id": "d4ZsE08XRsJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = './dataset/train_answer_modified.json'\n",
        "classes = ['yes', 'no']\n",
        "\n",
        "images, dataset_size, coco = filterDataset(folder, classes)"
      ],
      "metadata": {
        "id": "Kf67hVaaRoj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getImage(imageObj, img_folder, input_image_size):\n",
        "    # Read and normalize an image\n",
        "    train_img = io.imread(img_folder + '/' + imageObj['file_name'])/255.0\n",
        "    # Resize\n",
        "    train_img = cv2.resize(train_img, input_image_size)\n",
        "    if (len(train_img.shape)==3 and train_img.shape[2]==3): # If it is a RGB 3 channel image\n",
        "        return train_img\n",
        "    else: # To handle a black and white image, increase dimensions to 3\n",
        "        stacked_img = np.stack((train_img,)*3, axis=-1)\n",
        "        return stacked_img\n",
        "    \n",
        "def getNormalMask(imageObj, classes, coco, catIds, input_image_size):\n",
        "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    cats = coco.loadCats(catIds)\n",
        "    train_mask = np.zeros(input_image_size)\n",
        "    for a in range(len(anns)):\n",
        "        className = getClassName(anns[a]['category_id'], cats)\n",
        "        pixel_value = classes.index(className)+1\n",
        "        new_mask = cv2.resize(coco.annToMask(anns[a])*pixel_value, input_image_size)\n",
        "        train_mask = np.maximum(new_mask, train_mask)\n",
        "\n",
        "    # Add extra dimension for parity with train_img size [X * X * 3]\n",
        "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
        "    return train_mask  \n",
        "    \n",
        "def getBinaryMask(imageObj, coco, catIds, input_image_size):\n",
        "    annIds = coco.getAnnIds(imageObj['id'], catIds=catIds, iscrowd=None)\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    train_mask = np.zeros(input_image_size)\n",
        "    for a in range(len(anns)):\n",
        "        new_mask = cv2.resize(coco.annToMask(anns[a]), input_image_size)\n",
        "        \n",
        "        #Threshold because resizing may cause extraneous values\n",
        "        new_mask[new_mask >= 0.5] = 1\n",
        "        new_mask[new_mask < 0.5] = 0\n",
        "\n",
        "        train_mask = np.maximum(new_mask, train_mask)\n",
        "\n",
        "    # Add extra dimension for parity with train_img size [X * X * 3]\n",
        "    train_mask = train_mask.reshape(input_image_size[0], input_image_size[1], 1)\n",
        "    return train_mask\n",
        "\n",
        "\n",
        "def dataGeneratorCoco(images, classes, coco, folder, \n",
        "                      input_image_size=(224,224), batch_size=4, mode=\"train\", val_idx=300, mask_type='binary'):\n",
        "    img_folder = folder\n",
        "    dataset_size = len(images)\n",
        "    catIds = coco.getCatIds(catNms=classes)\n",
        "    \n",
        "    if mode == \"train\":\n",
        "      c=0\n",
        "    else:\n",
        "      c=val_idx\n",
        "\n",
        "    while(True):\n",
        "        img = np.zeros((batch_size, input_image_size[0], input_image_size[1], 3)).astype('float')\n",
        "        mask = np.zeros((batch_size, input_image_size[0], input_image_size[1], 1)).astype('float')\n",
        "\n",
        "        for i in range(c, c+batch_size): #initially from 0 to batch_size, when c = 0\n",
        "            imageObj = images[i]\n",
        "            \n",
        "            ### Retrieve Image ###\n",
        "            train_img = getImage(imageObj, img_folder, input_image_size)\n",
        "            \n",
        "            ### Create Mask ###\n",
        "            if mask_type==\"binary\":\n",
        "                train_mask = getBinaryMask(imageObj, coco, catIds, input_image_size)\n",
        "            \n",
        "            elif mask_type==\"normal\":\n",
        "                train_mask = getNormalMask(imageObj, classes, coco, catIds, input_image_size)                \n",
        "            \n",
        "            # Add to respective batch sized arrays\n",
        "            img[i-c] = train_img\n",
        "            mask[i-c] = train_mask\n",
        "            \n",
        "        c+=batch_size\n",
        "        if(c + batch_size >= dataset_size):\n",
        "            if mode == \"train\":\n",
        "              c=0\n",
        "            else:\n",
        "              c=val_idx\n",
        "            random.shuffle(images)\n",
        "        yield img, mask"
      ],
      "metadata": {
        "id": "sR3Db_HoR0H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "input_image_size = (224,224)\n",
        "mask_type = 'binary'\n",
        "img_folder = \"./dataset/train/\"\n",
        "val_gen = dataGeneratorCoco(images, classes, coco, img_folder, \n",
        "                            input_image_size, batch_size, mask_type)"
      ],
      "metadata": {
        "id": "rjiuuVefR07C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualizeGenerator(gen):\n",
        "    # Iterate the generator to get image and mask batches\n",
        "    img, mask = next(gen)\n",
        " \n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    outerGrid = gridspec.GridSpec(1, 2, wspace=0.1, hspace=0.1)\n",
        "   \n",
        "    for i in range(2):        \n",
        "        innerGrid = gridspec.GridSpecFromSubplotSpec(2, 2, subplot_spec=outerGrid[i], wspace=0.05, hspace=0.05)\n",
        "\n",
        "        for j in range(4):\n",
        "            ax = plt.Subplot(fig, innerGrid[j])\n",
        "            if(i==1):\n",
        "                ax.imshow(img[j]);\n",
        "            else:\n",
        "                ax.imshow(mask[j][:,:,0]);\n",
        "                \n",
        "            ax.axis('off')\n",
        "            fig.add_subplot(ax)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7B3qqgKbR1kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizeGenerator(val_gen)"
      ],
      "metadata": {
        "id": "mdNliUNOR2si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augmentationsGenerator(gen, augGeneratorArgs, seed=None):\n",
        "    # Initialize the image data generator with args provided\n",
        "    image_gen = ImageDataGenerator(**augGeneratorArgs)\n",
        "    \n",
        "    # Remove the brightness argument for the mask. Spatial arguments similar to image.\n",
        "    augGeneratorArgs_mask = augGeneratorArgs.copy()\n",
        "    _ = augGeneratorArgs_mask.pop('brightness_range', None)\n",
        "    # Initialize the mask data generator with modified args\n",
        "    mask_gen = ImageDataGenerator(**augGeneratorArgs_mask)\n",
        "    \n",
        "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
        "    \n",
        "    for img, mask in gen:\n",
        "        seed = np.random.choice(range(9999))\n",
        "        # keep the seeds syncronized otherwise the augmentation of the images \n",
        "        # will end up different from the augmentation of the masks\n",
        "        g_x = image_gen.flow(255*img, \n",
        "                             batch_size = img.shape[0], \n",
        "                             seed = seed, \n",
        "                             shuffle=True)\n",
        "        g_y = mask_gen.flow(mask, \n",
        "                             batch_size = mask.shape[0], \n",
        "                             seed = seed, \n",
        "                             shuffle=True)\n",
        "        \n",
        "        img_aug = next(g_x)/255.0\n",
        "        mask_aug = next(g_y)\n",
        "                   \n",
        "        yield img_aug, mask_aug"
      ],
      "metadata": {
        "id": "7Cyxuz21R3wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augGeneratorArgs = dict(featurewise_center = False, \n",
        "                        samplewise_center = False,\n",
        "                        rotation_range = 5, \n",
        "                        width_shift_range = 0.01, \n",
        "                        height_shift_range = 0.01, \n",
        "                        brightness_range = (0.8,1.2),\n",
        "                        shear_range = 0.01,\n",
        "                        zoom_range = [1, 1.25],  \n",
        "                        horizontal_flip = True, \n",
        "                        vertical_flip = False,\n",
        "                        fill_mode = 'reflect',\n",
        "                        data_format = 'channels_last')\n",
        "\n",
        "# Call the function with the arguments\n",
        "aug_gen = augmentationsGenerator(val_gen, augGeneratorArgs)"
      ],
      "metadata": {
        "id": "n4YJzdNPR49Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizeGenerator(aug_gen)"
      ],
      "metadata": {
        "id": "xaJf2I5pR6AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train segmentation model"
      ],
      "metadata": {
        "id": "yzFsoPDxR9aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers.core import Dropout, Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "zXTkt5pmR6s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-> Create filtered train dataset (using filterDataset()) \n",
        "#-> Create filtered val dataset (using filterDataset()) \n",
        "\n",
        "#-> Create train generator (using dataGeneratorCoco()) \n",
        "#-> Create train generator (using dataGeneratorCoco()) \n",
        "batch_size = 10\n",
        "train_batch_size = 200\n",
        "val_batch_size = 200\n",
        "\n",
        "input_image_size = (224,224)\n",
        "mask_type = 'binary'\n",
        "img_folder = \"./dataset/train/\"\n",
        "train_gen = dataGeneratorCoco(images, classes, coco, img_folder, \n",
        "                            input_image_size=input_image_size, batch_size=train_batch_size, mode=\"train\", val_idx=0, mask_type=mask_type)\n",
        "val_gen = dataGeneratorCoco(images, classes, coco, img_folder, \n",
        "                            input_image_size=input_image_size, batch_size=val_batch_size, mode=\"val\", val_idx=300, mask_type=mask_type)\n",
        "\n",
        "\n",
        "\n",
        "# Set your parameters\n",
        "n_epochs = 20\n",
        "steps_per_epoch = train_batch_size // batch_size\n",
        "validation_steps = val_batch_size // batch_size\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(224, 224, 3)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same'))\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "# Compile your model first\n",
        "model.compile(loss = \"mse\", optimizer = \"adam\", metrics=['accuracy'])\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "        \"segment_model_hjk.hdf5\",\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "stopping = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1, mode='min')\n",
        "csv_logger = CSVLogger(\n",
        "        \"/segment_model_hjk.log\",\n",
        "        separator=\",\",\n",
        "        append=True,\n",
        "    )\n",
        "\n",
        "print(\"Training is going to start in 3... 2... 1... \")\n",
        "\n",
        "H = model.fit(\n",
        "        x = train_gen,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        validation_data = val_gen,\n",
        "        validation_steps=validation_steps,\n",
        "        epochs=n_epochs,\n",
        "        verbose = True,\n",
        "        callbacks=[model_checkpoint, stopping, csv_logger],\n",
        "    )"
      ],
      "metadata": {
        "id": "mqiw7fb7R7RR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}